{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhebeJ/Project/blob/main/IRIS_LOCALIZATION_and_NORMALIZATION_for_image1_folder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3LXpyZT53wL"
      },
      "source": [
        "# **IRIS LOCALIZATION AND NORMALIZATION**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qs376dvcDUZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6506b96b-ba65-4403-9727-ef6587210aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQQ56fMl6KL-"
      },
      "source": [
        "### **IRIS LOCALIZATION**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pofMVEGrjm_E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W_uY17i4rRWF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from skimage import transform, feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UJ7DFnNY2UwG"
      },
      "outputs": [],
      "source": [
        "def read_imgs():\n",
        "    \"\"\"read all images of CASIA Iris Image Database (version 1.0)\n",
        "    :return: the train set and test set\n",
        "    :rtype: tuple (train, test)\n",
        "    \"\"\"\n",
        "\n",
        "    base_dir = '/gdrive/MyDrive/Images'\n",
        "    classes = os.listdir(base_dir)\n",
        "    train, test = [], []\n",
        "    for c in classes:\n",
        "        tr_dir = '%s/%s/1/' % (base_dir, c)\n",
        "        te_dir = '%s/%s/2/' % (base_dir, c)\n",
        "        for f in os.listdir(tr_dir):\n",
        "            if f[-3:] == 'bmp':\n",
        "                train.append(cv2.imread(tr_dir + f, 0))\n",
        "        for f in os.listdir(te_dir):\n",
        "            if f[-3:] == 'bmp':\n",
        "                test.append(cv2.imread(te_dir + f, 0))\n",
        "    print(\"Training output:\", train)\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV-9VdEl6Ri4"
      },
      "source": [
        "### **IRIS NORMALIZATION**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4z9q1W2r41Sy"
      },
      "outputs": [],
      "source": [
        "#NORMALIZATION\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def iris_normalization(img, pupil_circle, iris_circle, M=64, N=512, offset=0):\n",
        "    \"\"\"normalize the iris.\n",
        "    :param img: the input img\n",
        "    :param pupil_circle: (x, y, radius)\n",
        "    :param iris_circle: (x, y, radius)\n",
        "    :param M, N: the normalization image size\n",
        "    :param offset: the initial angle\n",
        "    :return: the normalization image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    normalized = np.zeros((M, N))\n",
        "    theta = np.linspace(0, 2 * np.pi, N)\n",
        "\n",
        "    for i in range(N):\n",
        "        curr_theta = theta[i] + offset\n",
        "        if curr_theta > 2 * np.pi:\n",
        "            curr_theta -= 2 * np.pi\n",
        "        begin = trans_axis(pupil_circle, curr_theta)\n",
        "        end = trans_axis(iris_circle, curr_theta)\n",
        "\n",
        "        xspace = np.linspace(begin[0], end[0], M)\n",
        "        yspace = np.linspace(begin[1], end[1], M)\n",
        "        normalized[:, i] = [255 - img[int(y), int(x)]\n",
        "                            if 0 <= int(x) < img.shape[1] and 0 <= int(y) < img.shape[0]\n",
        "                            else 0\n",
        "                            for x, y in zip(xspace, yspace)]\n",
        "    return normalized\n",
        "\n",
        "def trans_axis(circle, theta):\n",
        "    \"\"\"Changes polar coordinates to cartesian coordinate system.\n",
        "    :param circle: (x, y, radius)\n",
        "    :param theta: angle\n",
        "    :return: new coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    x0, y0, r = circle\n",
        "    x = int(x0 + r * math.cos(theta))\n",
        "    y = int(y0 + r * math.sin(theta))\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMAGE ENHANCEMENT**"
      ],
      "metadata": {
        "id": "udhCFZWeiehG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hCxHxYREA_ip"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from skimage.filters import rank\n",
        "import skimage.morphology as morp\n",
        "\n",
        "def enhance_img(img):\n",
        "    \"\"\"actually, the enhance method is based on another Ma Li's paper.\n",
        "        'Iris Recognition Based on Multichannel Gabor Filtering'\n",
        "    :param img: the input img\n",
        "    :return: the enhanced image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "    kernel = morp.disk(32)\n",
        "    img_local = rank.equalize(img.astype(np.uint8), selem=kernel)\n",
        "\n",
        "    enhanced = cv2.GaussianBlur(img_local, (5, 5), 0)\n",
        "    return enhanced"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zMDzh3cciuh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RB98v6DE2bcz"
      },
      "outputs": [],
      "source": [
        "def process_imgs(imgs, use_offset=False):\n",
        "    \"\"\"process the input raw images to feature vectors\n",
        "    :imgs: the image set\n",
        "    :use_offset: in the paper, it denotes unwrapping the iris with different angles can\n",
        "    remove rotation invariance. However, it seems no effect.\n",
        "    :return: the train set and test set\n",
        "    :rtype: tuple (train, test)\n",
        "    \"\"\"\n",
        "\n",
        "    processed = []\n",
        "    for img in imgs:\n",
        "        circles = detect_by_hough(img)\n",
        "        circles = np.array(circles).reshape(1 ,2 ,3)\n",
        "\n",
        "        # denoising\n",
        "        (_, B) = cv2.threshold(img ,180 ,255 ,cv2.THRESH_BINARY)\n",
        "        (_, C) = cv2.threshold(img ,100 ,255 ,cv2.THRESH_BINARY)\n",
        "        img = img & ~B & C\n",
        "\n",
        "        if use_offset:\n",
        "            offsets = [-9 ,-6 ,-3 ,0 ,3 ,6 ,9]\n",
        "\n",
        "            for offset in offsets:\n",
        "                normalized = iris_normalization(img,\n",
        "                                                circles[0][0], circles[0][1],\n",
        "                                                offset=offset)\n",
        "                enhanced = enhance_img(normalized)\n",
        "\n",
        "                ROI = enhanced[0:48]\n",
        "                print(\"ROI is:\", ROI)\n",
        "                filtered_1, _ = defined_gabor(ROI, frequency=0.1, sigma_x=3, sigma_y=1.5)\n",
        "                print(\"filtered_1 is:\", filtered_1)\n",
        "                filtered_2, _ = defined_gabor(ROI, frequency=0.07, sigma_x=4.5, sigma_y=1.5)\n",
        "                print(\"filtered_2 is\", filtered_2)\n",
        "                feature_vector = get_feature_vector(filtered_1, filtered_2)\n",
        "                print(\"feature_vector is\", feature_vector)\n",
        "                processed.append(feature_vector)\n",
        "\n",
        "        else:\n",
        "            normalized = iris_normalization(img, circles[0][0], circles[0][1])\n",
        "            enhanced = enhance_img(normalized)\n",
        "            ROI = enhanced[0:48]\n",
        "            print(\"ROI is:\", ROI)\n",
        "            filtered_1, _ = defined_gabor(ROI, frequency= 32 *np. pi /180, sigma_x=3, sigma_y=1.5)\n",
        "            print(\"filtered_1 is:\", filtered_1)\n",
        "            filtered_2, _ = defined_gabor(ROI, frequency= 32 *np. pi /180, sigma_x=4.5, sigma_y=1.5)\n",
        "            print(\"filtered_2 is\", filtered_2)\n",
        "            feature_vector = get_feature_vector(filtered_1, filtered_2)\n",
        "            print(\"feature_vector is\", feature_vector)\n",
        "            processed.append(feature_vector)\n",
        "\n",
        "        print ('processed imgs: %i/%i' % (len(processed), len(imgs)), end='\\r')\n",
        "\n",
        "    return ROI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RcwQZga22g3z"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    train_imgs, test_imgs = read_imgs()\n",
        "\n",
        "    train = process_imgs(train_imgs, use_offset=False)\n",
        "    train_labels = np.repeat(range(108), 3)\n",
        "    print(\"train_labels are:\", train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IX8gA02TrRgs"
      },
      "outputs": [],
      "source": [
        "def detect_by_hough(img):\n",
        "    \"\"\"preprocess the image, then use hough transform to detect both pupil and iris.\n",
        "    :param img: the input image\n",
        "    :return: the circles of pupil and iris, (x, y, radius), (x, y, radius)\n",
        "    :rtype: tuple\n",
        "    \"\"\"\n",
        "\n",
        "    #I have used the roughly_localize method, since it is error-prone.\n",
        "\n",
        "    def preprocess(img, pupil=False):\n",
        "        # respectively process pupil and iris\n",
        "        if pupil:\n",
        "            thresh = cv2.adaptiveThreshold(img, 255,\n",
        "                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                           cv2.THRESH_BINARY, 5, 3)\n",
        "            blur = cv2.GaussianBlur(thresh, (9, 9), 0)\n",
        "            blur = cv2.medianBlur(blur, 33)\n",
        "            #\n",
        "            canny = cv2.Canny(blur, 15, 50)\n",
        "        else:\n",
        "            blured = img.copy()\n",
        "            for i in range(3):\n",
        "                blured = cv2.medianBlur(blured, 11)\n",
        "            canny = cv2.Canny(blured, 15, 30)\n",
        "            canny[:,\n",
        "            pupil_circle[0] - pupil_circle[2] - 30:pupil_circle[0] + pupil_circle[2] + 30] = 0\n",
        "            canny[0:pupil_circle[1] - pupil_circle[2]] = 0\n",
        "\n",
        "        return canny\n",
        "\n",
        "    canny = preprocess(img, pupil=True)\n",
        "\n",
        "    pupil_circle = customed_hough_circle(canny, hough_radii=range(30, 70, 5))\n",
        "\n",
        "    # slightly enlarge the radius of pupil\n",
        "    pupil_circle[2] += 10\n",
        "\n",
        "    canny = preprocess(img)\n",
        "\n",
        "    iris_circle = customed_hough_circle(canny, hough_radii=range(pupil_circle[2] + 50, 150, 5))  # circles[0][0]\n",
        "\n",
        "    # if the distance of iris center and pupil center is too far, we fix the iris center.\n",
        "    if ((iris_circle - pupil_circle)[:2] ** 2).sum() ** 0.5 > pupil_circle[-1] * 0.3:\n",
        "        iris_circle[:2] = pupil_circle[:2]\n",
        "\n",
        "    return pupil_circle, iris_circle\n",
        "\n",
        "\n",
        "def get_pupil_roughly(img, binarize=False):\n",
        "    \"\"\"roughly localize pupil, using the method introduced in the paper.\n",
        "    :param img: the input image\n",
        "    :param binarize: whether binarize the img firstly\n",
        "    :return: the center coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    if binarize:\n",
        "        (_, img) = cv2.threshold(img,\n",
        "                                 0, 255,\n",
        "                                 cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    x_min = img.sum(axis=0).argmin()\n",
        "    y_min = img.sum(axis=1).argmin()\n",
        "\n",
        "    return x_min, y_min\n",
        "\n",
        "\n",
        "def select_region(img, x_min, y_min, size=60):\n",
        "    \"\"\"select a square  region centered at (x_min, y_min).\n",
        "    :param img: the input image\n",
        "    :param x_min, y_min: the center coordinates\n",
        "    :param size: the range\n",
        "    :return: the selected image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    size = min(x_min, y_min, size)\n",
        "    return img[y_min - size:y_min + size, x_min - size:x_min + size]\n",
        "\n",
        "\n",
        "def roughly_localize(img, size=60):\n",
        "    \"\"\"the whole procedure of roughly localizing pupil.\n",
        "    :param img: the input image\n",
        "    :param size: the range\n",
        "    :return: the center coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    x_min, y_min = get_pupil_roughly(img)\n",
        "\n",
        "    # the coordinates should not be off center too much.\n",
        "    if abs(x_min - 160) > 30:\n",
        "        x_min = 160\n",
        "    if abs(y_min - 140) > 30:\n",
        "        y_min = 140\n",
        "\n",
        "    # localize 2 times.\n",
        "    for i in range(2):\n",
        "        x, y = get_pupil_roughly(select_region(img, x_min, y_min, size=size),\n",
        "                                 binarize=True)\n",
        "        if abs(x_min - 160) > 30 or abs(y_min - 140) > 30:\n",
        "            break\n",
        "        x_min -= size - x\n",
        "        y_min -= size - y\n",
        "\n",
        "    return x_min, y_min\n",
        "\n",
        "\n",
        "def customed_hough_circle(img, hough_radii=range(30, 60)):\n",
        "    \"\"\"find circles on given img.\n",
        "    :param img: the input image\n",
        "    :param hough_radii: the radii of candidate circles\n",
        "    :return: the best circle, (x, y, radius)\n",
        "    :rtype: tuple (int, int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    hough_res = transform.hough_circle(img, hough_radii)\n",
        "    centers = []\n",
        "    accums = []\n",
        "    radii = []\n",
        "\n",
        "    for radius, h in zip(hough_radii, hough_res):\n",
        "        num_peaks = 10\n",
        "        peaks = feature.peak_local_max(h, num_peaks=num_peaks)\n",
        "        centers.extend(peaks)\n",
        "        accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
        "        radii.extend([radius] * num_peaks)\n",
        "    best = np.argsort(accums)[::-1][0]\n",
        "    return np.array([centers[best][1], centers[best][0], radii[best]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "\n",
        "from skimage.util import view_as_blocks\n",
        "\n",
        "def get_feature_vector(filtered_1, filtered_2):\n",
        "    \"\"\"As the paper denotes, this method generate the feature vector\n",
        "    based on the two filtered image.\n",
        "    :param filtered_1: the filtered image 1\n",
        "    :param filtered_2: the filtered image 2\n",
        "    :return: the feature vector\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    blocks_1 = view_as_blocks(filtered_1, block_shape=(8, 8)).reshape([-1, 64])\n",
        "    blocks_2 = view_as_blocks(filtered_2, block_shape=(8, 8)).reshape([-1, 64])\n",
        "\n",
        "    def mad(array, axis):\n",
        "        return np.mean(np.abs(array - np.mean(array, axis, keepdims=True)), axis)\n",
        "\n",
        "    m_1 = blocks_1.mean(axis=-1)\n",
        "    m_2 = blocks_2.mean(axis=-1)\n",
        "    mad_1 = mad(blocks_1, axis=-1)\n",
        "    mad_2 = mad(blocks_2, axis=-1)\n",
        "\n",
        "    #     feature_vector = np.concatenate([np.stack([m_1, mad_1], axis=1).reshape([-1]),\n",
        "    #                                     np.stack([m_2, mad_2], axis=1).reshape([-1])])\n",
        "    feature_vector = np.stack([m_1, mad_1, m_2, mad_2], axis=1).reshape([-1])\n",
        "    print(\"Feature Vector inside get_feature_vector:\", feature_vector)\n",
        "    return feature_vector\n",
        "\n",
        "def defined_gabor_kernel(frequency, sigma_x=None, sigma_y=None,\n",
        "                         n_stds=3, offset=0, theta=0):\n",
        "    \"\"\"\n",
        "    According to the codes of skimage, I directly rewrote the function gabor_kernel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    frequency : float\n",
        "        Spatial frequency of the harmonic function. Specified in pixels.\n",
        "    theta : float, optional\n",
        "        Orientation in radians. If 0, the harmonic is in the x-direction.\n",
        "    sigma_x, sigma_y : float, optional\n",
        "        Standard deviation in x- and y-directions. These directions apply to\n",
        "        the kernel *before* rotation. If `theta = pi/2`, then the kernel is\n",
        "        rotated 90 degrees so that `sigma_x` controls the *vertical* direction.\n",
        "    n_stds : scalar, optional\n",
        "        The linear size of the kernel is n_stds (3 by default) standard\n",
        "        deviations\n",
        "    offset : float, optional\n",
        "        Phase offset of harmonic function in radians.\n",
        "    Returns\n",
        "    -------\n",
        "    g : complex array\n",
        "        Complex filter kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    x0 = np.ceil(max(np.abs(n_stds * sigma_x * np.cos(theta)),\n",
        "                     np.abs(n_stds * sigma_y * np.sin(theta)), 1))\n",
        "    y0 = np.ceil(max(np.abs(n_stds * sigma_y * np.cos(theta)),\n",
        "                     np.abs(n_stds * sigma_x * np.sin(theta)), 1))\n",
        "    y, x = np.mgrid[-y0:y0 + 1, -x0:x0 + 1]\n",
        "\n",
        "    g = np.zeros(y.shape, dtype=np.complex)\n",
        "    g[:] = np.exp(-0.5 * (x ** 2 / sigma_x ** 2 + y ** 2 / sigma_y ** 2))\n",
        "    g /= 2 * np.pi * sigma_x * sigma_y\n",
        "    g *= np.cos(2 * np.pi * frequency * ((x ** 2 + y ** 2) ** 0.5))\n",
        "    print(\"g is:\", g)\n",
        "    return g\n",
        "\n",
        "\n",
        "def defined_gabor(img, frequency, sigma_x, sigma_y):\n",
        "    \"\"\"\n",
        "    Perform gabor filter on the image using defined kernel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    param img : the input img\n",
        "    frequency : float\n",
        "        Spatial frequency of the harmonic function. Specified in pixels.\n",
        "    sigma_x, sigma_y : float, optional\n",
        "        Standard deviation in x- and y-directions. These directions apply to\n",
        "        the kernel *before* rotation. If `theta = pi/2`, then the kernel is\n",
        "        rotated 90 degrees so that `sigma_x` controls the *vertical* direction.\n",
        "    -------\n",
        "    Returns   :\n",
        "    filtered_real, filtered_imag : the filtered image. Because using the evensymmetric\n",
        "    filter, the filtered_imag is zero.\n",
        "    \"\"\"\n",
        "\n",
        "    g = defined_gabor_kernel(frequency, sigma_x, sigma_y)\n",
        "    filtered_real = ndi.convolve(img, np.real(g), mode='wrap', cval=0)\n",
        "    filtered_imag = ndi.convolve(img, np.imag(g), mode='wrap', cval=0)\n",
        "    print(\"filtered_real is:\", filtered_real)\n",
        "    print(\"filtered_imag is:\", filtered_imag)\n",
        "    return filtered_real, filtered_imag\n",
        "\n"
      ],
      "metadata": {
        "id": "eGojuVOTMIt1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T2mGCvNE2zC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0304fb15-44af-449c-c20f-c39ac02c6431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training output: [array([[176, 166, 170, ..., 187, 180, 169],\n",
            "       [170, 169, 173, ..., 185, 181, 179],\n",
            "       [177, 165, 173, ..., 198, 187, 169],\n",
            "       ...,\n",
            "       [154, 155, 155, ..., 169, 178, 199],\n",
            "       [159, 148, 154, ..., 170, 177, 192],\n",
            "       [153, 154, 150, ..., 172, 171, 189]], dtype=uint8), array([[193, 180, 187, ..., 186, 183, 185],\n",
            "       [180, 180, 180, ..., 185, 187, 178],\n",
            "       [182, 186, 178, ..., 193, 184, 176],\n",
            "       ...,\n",
            "       [167, 163, 167, ..., 180, 185, 186],\n",
            "       [170, 165, 154, ..., 178, 182, 198],\n",
            "       [165, 166, 170, ..., 186, 205, 189]], dtype=uint8), array([[158, 164, 165, ..., 180, 185, 180],\n",
            "       [168, 154, 169, ..., 184, 185, 178],\n",
            "       [161, 162, 170, ..., 191, 177, 179],\n",
            "       ...,\n",
            "       [145, 142, 147, ..., 177, 174, 172],\n",
            "       [137, 144, 142, ..., 186, 167, 181],\n",
            "       [131, 141, 148, ..., 175, 174, 177]], dtype=uint8), array([[182, 176, 195, ..., 182, 178, 178],\n",
            "       [185, 197, 181, ..., 174, 176, 178],\n",
            "       [188, 190, 186, ..., 183, 173, 174],\n",
            "       ...,\n",
            "       [185, 183, 186, ..., 200, 209, 196],\n",
            "       [188, 175, 194, ..., 206, 202, 200],\n",
            "       [187, 181, 184, ..., 194, 205, 190]], dtype=uint8), array([[182, 185, 192, ..., 188, 185, 194],\n",
            "       [185, 190, 205, ..., 184, 190, 179],\n",
            "       [188, 198, 196, ..., 192, 183, 174],\n",
            "       ...,\n",
            "       [167, 175, 171, ..., 195, 193, 197],\n",
            "       [162, 167, 164, ..., 190, 198, 197],\n",
            "       [162, 167, 169, ..., 198, 194, 198]], dtype=uint8), array([[182, 179, 194, ..., 179, 182, 189],\n",
            "       [183, 179, 193, ..., 182, 188, 180],\n",
            "       [187, 179, 189, ..., 188, 181, 187],\n",
            "       ...,\n",
            "       [172, 176, 192, ..., 201, 198, 194],\n",
            "       [179, 170, 184, ..., 194, 201, 196],\n",
            "       [195, 160, 182, ..., 197, 196, 194]], dtype=uint8)]\n",
            "ROI is: [[230 236 244 ... 243 230 222]\n",
            " [223 228 236 ... 239 226 219]\n",
            " [209 212 220 ... 229 217 210]\n",
            " ...\n",
            " [130 131 140 ... 125 125 118]\n",
            " [133 127 123 ... 119 126 123]\n",
            " [127 116  96 ... 120 118 111]]\n",
            "filtered_1 is: [[253 253 253 ... 253 253 253]\n",
            " [252 252 252 ... 252 252 252]\n",
            " [252 252 252 ... 252 252 252]\n",
            " ...\n",
            " [255 254 254 ... 255 254 254]\n",
            " [254 254 255 ... 255 254 255]\n",
            " [253 253 253 ... 253 253 253]]\n",
            "filtered_2 is [[254 254 254 ... 254 254 254]\n",
            " [254 254 253 ... 253 253 254]\n",
            " [254 254 254 ... 253 254 254]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [254 254 254 ... 254 254 254]]\n",
            "feature_vector is [253.           0.8125     238.203125   ...  15.36816406 238.71875\n",
            "  29.83984375]\n",
            "ROI is: [[222 225 229 ... 213 196 188]\n",
            " [219 223 228 ... 215 195 184]\n",
            " [207 212 217 ... 212 184 168]\n",
            " ...\n",
            " [187 195 202 ... 142 128 120]\n",
            " [186 189 187 ... 121 104  95]\n",
            " [177 175 162 ...  84  80  78]]\n",
            "filtered_1 is: [[253 253 253 ... 254 254 254]\n",
            " [253 252 252 ... 252 253 252]\n",
            " [253 252 252 ... 252 253 253]\n",
            " ...\n",
            " [254 253 253 ... 254 255 254]\n",
            " [254 252 253 ... 254   0 254]\n",
            " [254 251 253 ... 253 255 253]]\n",
            "filtered_2 is [[254 254 254 ... 255 255 255]\n",
            " [254 254 253 ... 254 254 254]\n",
            " [254 253 254 ... 254 254 254]\n",
            " ...\n",
            " [255 254 254 ... 255 255 255]\n",
            " [255 253 255 ... 255   0 255]\n",
            " [255 253 254 ... 254 255 254]]\n",
            "feature_vector is [253.484375     0.734375   246.515625   ...   7.79199219 238.375\n",
            "  29.796875  ]\n",
            "ROI is: [[236 239 240 ... 165 180 189]\n",
            " [217 222 229 ... 163 165 167]\n",
            " [162 171 184 ... 145 124 113]\n",
            " ...\n",
            " [ 62  57  53 ... 168 161 151]\n",
            " [ 66  60  53 ... 161 138 119]\n",
            " [ 71  68  67 ... 126  94  74]]\n",
            "filtered_1 is: [[254 253 254 ... 254 255 254]\n",
            " [253 251 252 ... 253 254 253]\n",
            " [254 253 253 ... 254 255 254]\n",
            " ...\n",
            " [255   0   0 ... 254 253 255]\n",
            " [255   0   0 ... 254 254 255]\n",
            " [254 253 254 ... 253 254 254]]\n",
            "filtered_2 is [[255 254 255 ... 255 255 255]\n",
            " [254 253 253 ... 254 255 254]\n",
            " [255 254 254 ... 254 255 255]\n",
            " ...\n",
            " [255   0   0 ... 255 254 255]\n",
            " [  0   0   0 ... 255 255   0]\n",
            " [255 254 255 ... 254 255 255]]\n",
            "feature_vector is [221.515625    55.37890625 198.546875   ...   0.60839844 230.5625\n",
            "  43.23046875]\n",
            "ROI is: [[169 172 182 ... 148 107  92]\n",
            " [168 171 182 ... 151 106  90]\n",
            " [171 175 186 ... 148 100  85]\n",
            " ...\n",
            " [224 215 204 ... 166 185 196]\n",
            " [232 230 227 ... 178 190 197]\n",
            " [220 225 234 ... 180 180 180]]\n",
            "filtered_1 is: [[254 252 253 ... 253 255 253]\n",
            " [254 253 253 ... 254   0 255]\n",
            " [254 253 253 ... 254 255 254]\n",
            " ...\n",
            " [252 252 253 ... 253 253 252]\n",
            " [253 252 252 ... 253 253 252]\n",
            " [253 252 252 ... 254 254 254]]\n",
            "filtered_2 is [[255 254 254 ... 254 255 254]\n",
            " [255 254 254 ... 255   0 255]\n",
            " [255 254 254 ... 255   0 255]\n",
            " ...\n",
            " [254 254 254 ... 254 254 254]\n",
            " [254 254 254 ... 254 254 254]\n",
            " [254 254 254 ... 255 255 255]]\n",
            "feature_vector is [252.703125     0.63037109 254.03125    ...   7.79882812 222.5625\n",
            "  55.640625  ]\n",
            "ROI is: [[215 220 227 ...  98 100 110]\n",
            " [208 214 224 ...  99  96 104]\n",
            " [197 203 215 ... 103  89  94]\n",
            " ...\n",
            " [173 173 171 ... 119 126 134]\n",
            " [190 192 195 ... 145 153 161]\n",
            " [196 199 204 ... 171 180 185]]\n",
            "filtered_1 is: [[254 252 253 ... 254 255 252]\n",
            " [253 251 253 ... 255   0 254]\n",
            " [254 252 252 ... 255   0 254]\n",
            " ...\n",
            " [253 253 253 ... 254 254 253]\n",
            " [254 253 253 ... 254 253 253]\n",
            " [252 253 252 ... 255 254 254]]\n",
            "filtered_2 is [[255 253 254 ... 255 255 254]\n",
            " [254 253 254 ... 255   0 255]\n",
            " [255 254 254 ... 255   0 255]\n",
            " ...\n",
            " [254 254 254 ... 255 255 254]\n",
            " [255 254 254 ... 255 254 254]\n",
            " [254 254 253 ... 255 255 255]]\n",
            "feature_vector is [252.75         0.7265625  230.046875   ...   7.81982422 206.953125\n",
            "  77.60742188]\n",
            "ROI is: [[227 226 225 ... 135 132 135]\n",
            " [227 225 220 ... 132 129 133]\n",
            " [230 225 215 ... 128 125 132]\n",
            " ...\n",
            " [219 216 213 ... 159 159 159]\n",
            " [216 214 214 ... 149 145 142]\n",
            " [222 221 222 ... 143 143 142]]\n",
            "filtered_1 is: [[253 252 252 ... 254 255 253]\n",
            " [253 252 252 ... 254 255 253]\n",
            " [253 252 252 ... 254 255 253]\n",
            " ...\n",
            " [253 252 252 ... 254 254 253]\n",
            " [253 252 252 ... 253 254 253]\n",
            " [253 252 252 ... 254 255 253]]\n",
            "filtered_2 is [[254 253 254 ... 255 255 254]\n",
            " [254 253 254 ... 255   0 254]\n",
            " [254 253 254 ... 255   0 254]\n",
            " ...\n",
            " [254 254 254 ... 255 255 254]\n",
            " [254 253 254 ... 254 255 254]\n",
            " [254 253 254 ... 255 255 254]]\n",
            "feature_vector is [252.390625     0.66503906 241.859375   ...   7.81689453 198.90625\n",
            "  87.02148438]\n"
          ]
        }
      ],
      "source": [
        "if __name__ =='__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "IRIS LOCALIZATION and NORMALIZATION- for 1 image folder",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1F5ljTv7hmeEx9IDk1jOkYT2Fskh-ijnX",
      "authorship_tag": "ABX9TyPSvNHHvGs6RCucCSN7DuFh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}