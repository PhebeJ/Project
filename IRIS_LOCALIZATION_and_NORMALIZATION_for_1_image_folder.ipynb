{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhebeJ/Project/blob/main/IRIS_LOCALIZATION_and_NORMALIZATION_for_1_image_folder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3LXpyZT53wL"
      },
      "source": [
        "# **IRIS LOCALIZATION AND NORMALIZATION**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qs376dvcDUZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf239ad-1869-478c-cea3-6e70c8ef94eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQQ56fMl6KL-"
      },
      "source": [
        "### **IRIS LOCALIZATION**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pofMVEGrjm_E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "W_uY17i4rRWF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from skimage import transform, feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UJ7DFnNY2UwG"
      },
      "outputs": [],
      "source": [
        "def read_imgs():\n",
        "    \"\"\"read all images of CASIA Iris Image Database (version 1.0)\n",
        "    :return: the train set and test set\n",
        "    :rtype: tuple (train, test)\n",
        "    \"\"\"\n",
        "\n",
        "    base_dir = '/gdrive/MyDrive/Images'\n",
        "    classes = os.listdir(base_dir)\n",
        "    train, test = [], []\n",
        "    for c in classes:\n",
        "        tr_dir = '%s/%s/1/' % (base_dir, c)\n",
        "        te_dir = '%s/%s/2/' % (base_dir, c)\n",
        "        for f in os.listdir(tr_dir):\n",
        "            if f[-3:] == 'bmp':\n",
        "                train.append(cv2.imread(tr_dir + f, 0))\n",
        "        for f in os.listdir(te_dir):\n",
        "            if f[-3:] == 'bmp':\n",
        "                test.append(cv2.imread(te_dir + f, 0))\n",
        "    print(train)\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV-9VdEl6Ri4"
      },
      "source": [
        "### **IRIS NORMALIZATION**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4z9q1W2r41Sy"
      },
      "outputs": [],
      "source": [
        "#NORMALIZATION\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def iris_normalization(img, pupil_circle, iris_circle, M=64, N=512, offset=0):\n",
        "    \"\"\"normalize the iris.\n",
        "    :param img: the input img\n",
        "    :param pupil_circle: (x, y, radius)\n",
        "    :param iris_circle: (x, y, radius)\n",
        "    :param M, N: the normalization image size\n",
        "    :param offset: the initial angle\n",
        "    :return: the normalization image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    normalized = np.zeros((M, N))\n",
        "    theta = np.linspace(0, 2 * np.pi, N)\n",
        "\n",
        "    for i in range(N):\n",
        "        curr_theta = theta[i] + offset\n",
        "        if curr_theta > 2 * np.pi:\n",
        "            curr_theta -= 2 * np.pi\n",
        "        begin = trans_axis(pupil_circle, curr_theta)\n",
        "        end = trans_axis(iris_circle, curr_theta)\n",
        "\n",
        "        xspace = np.linspace(begin[0], end[0], M)\n",
        "        yspace = np.linspace(begin[1], end[1], M)\n",
        "        normalized[:, i] = [255 - img[int(y), int(x)]\n",
        "                            if 0 <= int(x) < img.shape[1] and 0 <= int(y) < img.shape[0]\n",
        "                            else 0\n",
        "                            for x, y in zip(xspace, yspace)]\n",
        "    return normalized\n",
        "\n",
        "def trans_axis(circle, theta):\n",
        "    \"\"\"Changes polar coordinates to cartesian coordinate system.\n",
        "    :param circle: (x, y, radius)\n",
        "    :param theta: angle\n",
        "    :return: new coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    x0, y0, r = circle\n",
        "    x = int(x0 + r * math.cos(theta))\n",
        "    y = int(y0 + r * math.sin(theta))\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMAGE ENHANCEMENT**"
      ],
      "metadata": {
        "id": "udhCFZWeiehG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hCxHxYREA_ip"
      },
      "outputs": [],
      "source": [
        " import cv2\n",
        "import numpy as np\n",
        "\n",
        "from skimage.filters import rank\n",
        "import skimage.morphology as morp\n",
        "\n",
        "def enhance_img(img):\n",
        "    \"\"\"actually, the enhance method is based on another Ma Li's paper.\n",
        "        'Iris Recognition Based on Multichannel Gabor Filtering'\n",
        "    :param img: the input img\n",
        "    :return: the enhanced image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "    kernel = morp.disk(32)\n",
        "    img_local = rank.equalize(img.astype(np.uint8), selem=kernel)\n",
        "\n",
        "    enhanced = cv2.GaussianBlur(img_local, (5, 5), 0)\n",
        "    return enhanced"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zMDzh3cciuh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RB98v6DE2bcz"
      },
      "outputs": [],
      "source": [
        "def process_imgs(imgs, use_offset=False):\n",
        "    \"\"\"process the input raw images to feature vectors\n",
        "    :imgs: the image set\n",
        "    :use_offset: in the paper, it denotes unwrapping the iris with different angles can\n",
        "    remove rotation invariance. However, it seems no effect.\n",
        "    :return: the train set and test set\n",
        "    :rtype: tuple (train, test)\n",
        "    \"\"\"\n",
        "\n",
        "    processed = []\n",
        "    for img in imgs:\n",
        "        circles = detect_by_hough(img)\n",
        "        circles = np.array(circles).reshape(1 ,2 ,3)\n",
        "\n",
        "        # denoising\n",
        "        (_, B) = cv2.threshold(img ,180 ,255 ,cv2.THRESH_BINARY)\n",
        "        (_, C) = cv2.threshold(img ,100 ,255 ,cv2.THRESH_BINARY)\n",
        "        img = img & ~B & C\n",
        "\n",
        "        if use_offset:\n",
        "            offsets = [-9 ,-6 ,-3 ,0 ,3 ,6 ,9]\n",
        "\n",
        "            for offset in offsets:\n",
        "                normalized = iris_normalization(img,\n",
        "                                                circles[0][0], circles[0][1],\n",
        "                                                offset=offset)\n",
        "                enhanced = enhance_img(normalized)\n",
        "\n",
        "                ROI = enhanced[0:48]\n",
        "\n",
        "        else:\n",
        "            normalized = iris_normalization(img, circles[0][0], circles[0][1])\n",
        "            enhanced = enhance_img(normalized)\n",
        "            ROI = enhanced[0:48]\n",
        "\n",
        "    return ROI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RcwQZga22g3z"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    train_imgs, test_imgs = read_imgs()\n",
        "\n",
        "    train = process_imgs(train_imgs, use_offset=False)\n",
        "    train_labels = np.repeat(range(108), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IX8gA02TrRgs"
      },
      "outputs": [],
      "source": [
        "def detect_by_hough(img):\n",
        "    \"\"\"preprocess the image, then use hough transform to detect both pupil and iris.\n",
        "    :param img: the input image\n",
        "    :return: the circles of pupil and iris, (x, y, radius), (x, y, radius)\n",
        "    :rtype: tuple\n",
        "    \"\"\"\n",
        "\n",
        "    #I have used the roughly_localize method, since it is error-prone.\n",
        "\n",
        "    def preprocess(img, pupil=False):\n",
        "        # respectively process pupil and iris\n",
        "        if pupil:\n",
        "            thresh = cv2.adaptiveThreshold(img, 255,\n",
        "                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                           cv2.THRESH_BINARY, 5, 3)\n",
        "            blur = cv2.GaussianBlur(thresh, (9, 9), 0)\n",
        "            blur = cv2.medianBlur(blur, 33)\n",
        "            #\n",
        "            canny = cv2.Canny(blur, 15, 50)\n",
        "        else:\n",
        "            blured = img.copy()\n",
        "            for i in range(3):\n",
        "                blured = cv2.medianBlur(blured, 11)\n",
        "            canny = cv2.Canny(blured, 15, 30)\n",
        "            canny[:,\n",
        "            pupil_circle[0] - pupil_circle[2] - 30:pupil_circle[0] + pupil_circle[2] + 30] = 0\n",
        "            canny[0:pupil_circle[1] - pupil_circle[2]] = 0\n",
        "\n",
        "        return canny\n",
        "\n",
        "    canny = preprocess(img, pupil=True)\n",
        "\n",
        "    pupil_circle = customed_hough_circle(canny, hough_radii=range(30, 70, 5))\n",
        "\n",
        "    # slightly enlarge the radius of pupil\n",
        "    pupil_circle[2] += 10\n",
        "\n",
        "    canny = preprocess(img)\n",
        "\n",
        "    iris_circle = customed_hough_circle(canny, hough_radii=range(pupil_circle[2] + 50, 150, 5))  # circles[0][0]\n",
        "\n",
        "    # if the distance of iris center and pupil center is too far, we fix the iris center.\n",
        "    if ((iris_circle - pupil_circle)[:2] ** 2).sum() ** 0.5 > pupil_circle[-1] * 0.3:\n",
        "        iris_circle[:2] = pupil_circle[:2]\n",
        "\n",
        "    return pupil_circle, iris_circle\n",
        "\n",
        "\n",
        "def get_pupil_roughly(img, binarize=False):\n",
        "    \"\"\"roughly localize pupil, using the method introduced in the paper.\n",
        "    :param img: the input image\n",
        "    :param binarize: whether binarize the img firstly\n",
        "    :return: the center coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    if binarize:\n",
        "        (_, img) = cv2.threshold(img,\n",
        "                                 0, 255,\n",
        "                                 cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    x_min = img.sum(axis=0).argmin()\n",
        "    y_min = img.sum(axis=1).argmin()\n",
        "\n",
        "    return x_min, y_min\n",
        "\n",
        "\n",
        "def select_region(img, x_min, y_min, size=60):\n",
        "    \"\"\"select a square  region centered at (x_min, y_min).\n",
        "    :param img: the input image\n",
        "    :param x_min, y_min: the center coordinates\n",
        "    :param size: the range\n",
        "    :return: the selected image\n",
        "    :rtype: ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    size = min(x_min, y_min, size)\n",
        "    return img[y_min - size:y_min + size, x_min - size:x_min + size]\n",
        "\n",
        "\n",
        "def roughly_localize(img, size=60):\n",
        "    \"\"\"the whole procedure of roughly localizing pupil.\n",
        "    :param img: the input image\n",
        "    :param size: the range\n",
        "    :return: the center coordinates (x, y)\n",
        "    :rtype: tuple (int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    x_min, y_min = get_pupil_roughly(img)\n",
        "\n",
        "    # the coordinates should not be off center too much.\n",
        "    if abs(x_min - 160) > 30:\n",
        "        x_min = 160\n",
        "    if abs(y_min - 140) > 30:\n",
        "        y_min = 140\n",
        "\n",
        "    # localize 2 times.\n",
        "    for i in range(2):\n",
        "        x, y = get_pupil_roughly(select_region(img, x_min, y_min, size=size),\n",
        "                                 binarize=True)\n",
        "        if abs(x_min - 160) > 30 or abs(y_min - 140) > 30:\n",
        "            break\n",
        "        x_min -= size - x\n",
        "        y_min -= size - y\n",
        "\n",
        "    return x_min, y_min\n",
        "\n",
        "\n",
        "def customed_hough_circle(img, hough_radii=range(30, 60)):\n",
        "    \"\"\"find circles on given img.\n",
        "    :param img: the input image\n",
        "    :param hough_radii: the radii of candidate circles\n",
        "    :return: the best circle, (x, y, radius)\n",
        "    :rtype: tuple (int, int, int)\n",
        "    \"\"\"\n",
        "\n",
        "    hough_res = transform.hough_circle(img, hough_radii)\n",
        "    centers = []\n",
        "    accums = []\n",
        "    radii = []\n",
        "\n",
        "    for radius, h in zip(hough_radii, hough_res):\n",
        "        num_peaks = 10\n",
        "        peaks = feature.peak_local_max(h, num_peaks=num_peaks)\n",
        "        centers.extend(peaks)\n",
        "        accums.extend(h[peaks[:, 0], peaks[:, 1]])\n",
        "        radii.extend([radius] * num_peaks)\n",
        "    best = np.argsort(accums)[::-1][0]\n",
        "    return np.array([centers[best][1], centers[best][0], radii[best]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2mGCvNE2zC7",
        "outputId": "ff05cd42-09cc-47fa-d19a-d39c0c1c3b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[176, 166, 170, ..., 187, 180, 169],\n",
            "       [170, 169, 173, ..., 185, 181, 179],\n",
            "       [177, 165, 173, ..., 198, 187, 169],\n",
            "       ...,\n",
            "       [154, 155, 155, ..., 169, 178, 199],\n",
            "       [159, 148, 154, ..., 170, 177, 192],\n",
            "       [153, 154, 150, ..., 172, 171, 189]], dtype=uint8), array([[193, 180, 187, ..., 186, 183, 185],\n",
            "       [180, 180, 180, ..., 185, 187, 178],\n",
            "       [182, 186, 178, ..., 193, 184, 176],\n",
            "       ...,\n",
            "       [167, 163, 167, ..., 180, 185, 186],\n",
            "       [170, 165, 154, ..., 178, 182, 198],\n",
            "       [165, 166, 170, ..., 186, 205, 189]], dtype=uint8), array([[158, 164, 165, ..., 180, 185, 180],\n",
            "       [168, 154, 169, ..., 184, 185, 178],\n",
            "       [161, 162, 170, ..., 191, 177, 179],\n",
            "       ...,\n",
            "       [145, 142, 147, ..., 177, 174, 172],\n",
            "       [137, 144, 142, ..., 186, 167, 181],\n",
            "       [131, 141, 148, ..., 175, 174, 177]], dtype=uint8)]\n"
          ]
        }
      ],
      "source": [
        "if __name__ =='__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "IRIS LOCALIZATION and NORMALIZATION- for 1 image folder",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1F5ljTv7hmeEx9IDk1jOkYT2Fskh-ijnX",
      "authorship_tag": "ABX9TyMnjaTA+xtbxG0Sp1VLyvdh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}